/////////////////////////////////
////Section 6 : The Perceptron //
////////////////////////////////

# Neural network (NN)
- inspired from biological neural
- it simulates the way the human (brain) learns

## The perceptron : 
    => 1 input layer
        => input nodes : x1*w1 + x2*w2 ...+ b
            where : 
            x : input signals
            b : bias 
            w : weights
    => Neuron 
        => Summation function
        => activation function (step : 0/1) 

    => 1 output layer 

- The multilayer perceptron forms fully connected NN 
    => 1 input layer 
    => multiple hidden layers
    => Neuron 
        => Summation function
        => activation functions (step, tanh, sigmoid, RELU...)

    => 1 output layer

## MACHINE LEARNING ##

- ML is the concept of building computational systems that learn overtime based on experience
=> ML : the ability to learn w/ data 

- ML workflow 
+------------+    +----------+     +----------+    +----------+
| Algorithms | => |  Learn   | =>  | Improve  | => | Predict  |
+------------+    +----------+     +----------+    +----------+

- ML Model types
    - Supervised learning (SP) : teach algo based on dataset(feature/label)
    - UnSupervised learning (USP) : large dataset, no label, find simularity/differency act in the info w/ (pre)training
    - Reinforcement learning (RL) : conceptually similar to human learning processes (ex : robot learn to walk, talk...)

=> Supervised learning (SP) algorithms/model
    - Regression
        => Linear 
        => Non-Linear 
    - Classification 
        => Linear model
        => Non-Linear 

//// Regression ////
- https://github.com/afondiel/computer-science-open-catalog/tree/master/ai/ml-notes
- https://github.com/afondiel/computer-science-open-catalog/blob/master/datascience-notes/certificates/coursera/ibm/ds-ibm-notes.txt
    => course 7 - W4 : Model dev
    => course 9 - W2 : Regression 

//// Classification ////
- https://github.com/afondiel/computer-science-open-catalog/tree/master/ai/ml-notes
- https://github.com/afondiel/computer-science-open-catalog/blob/master/datascience-notes/certificates/coursera/ibm/ds-ibm-notes.txt
    => Course 9 - W3 : Classification

### TRAINING/FITTING 

/!\ The characteristics of a Great Model : 
    => low error
    => high accuracy 


=> learning/working Technics : 
- Forward propagation : input data is fed in the forward direction through the network 
    => feed forward => input + hidden + output
- Back propagation : allows NN figure out patterns that are convoluted complex for human to extract
    => feed forward + calculate error + back propagation


#### Cost/Loss functions

* Regression 

- Most common Model evaluation metrics :
	=> MAE : Mean Absolute Error 
+--------------------------+
|MAE = 1/n*Sum(|yi - ^yi|) |
+--------------------------+
	=> MSE : Mean Squared error 
+--------------------------+
|MSE = 1/n*Sum(yi - ^yi)2  |
+--------------------------+
	=> RMSE : Root Mean Squared error 
+--------------------------+
|RMSE^2 = 1/n*Sum(yi - ^yi)|
+--------------------------+

	=> RAE : Relative Absolute Error/Residual sum of square 
+---------------------------+
|RAE = n*MAE/Sum(|yi - ÿi|) | where ÿ : mean of y 
+---------------------------+

	=> RSE : Relative Squared error : (very similar to MAE, is used for Normalization) => used to calculate R^2
+--------------------------------------+
|RSE = Sum(yi - ^yi)^2 / Sum(yi - ÿ)^2 |
+--------------------------------------+

- R squared  : represents how close the data values are to the fitted regression line 
=> the more R^2 is higher the more the model fitted the data  

[R^2 = 1 - RSE]  

## Classification 
- Cross-entropy loss (error calculation)


#### Optimization functions
    => Least Squares
    => Gradient Descent

#### Activation functions 
    => step () : 
        => 0 if score < 0
        => 1 if score >= 0 
    => sigmoid (logistic function)
    => tanh
    => SoftMax
    => RELU
    ...



# References 
The perceptron : 
https://en.wikipedia.org/wiki/Perceptron
Neural Network
https://www.youtube.com/watch?v=aircAruvnKk
SP vs USP vs RL
https://www.aitude.com/supervised-vs-unsupervised-vs-reinforcement/
